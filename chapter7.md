# 第7章：GPU 架构演进

> 从固定功能管线到可编程并行处理器的技术革命

## 本章概览

NVIDIA GPU架构的演进历程是现代计算史上最重要的技术革新之一。从1999年GeForce 256定义GPU概念开始，经过25年的发展，GPU已经从专用图形处理器演变为通用并行计算平台，成为AI时代的核心基础设施。

本章将深入剖析三个核心技术维度：
1. **SM（Streaming Multiprocessor）演化史**：从固定功能单元到高度可编程的并行处理器
2. **内存架构革新**：从DDR到HBM，解决"内存墙"问题的技术演进
3. **互连技术发展**：NVLink和NVSwitch如何打破PCIe瓶颈，实现超大规模GPU集群

## 1. SM (Streaming Multiprocessor) 演化史

### 1.1 前GPU时代：固定功能管线 (1995-1999)

在GPU概念诞生之前，图形加速器采用固定功能管线架构：

```
┌──────────────────────────────────────────────────┐
│            NV1/RIVA 128 固定管线                  │
├──────────────────────────────────────────────────┤
│  顶点处理 → 光栅化 → 纹理映射 → 像素输出          │
│     ↓         ↓         ↓          ↓            │
│  [固定单元] [固定单元] [固定单元] [固定单元]      │
└──────────────────────────────────────────────────┘
```

**技术特征**：
- 每个处理阶段都是专用硬件单元
- 无法编程，只能通过固定API控制
- 效率高但灵活性极差
- 无法适应新的渲染算法

### 1.2 第一代GPU：硬件T&L时代 (1999-2001)

**GeForce 256 (NV10)**：定义GPU概念，引入硬件T&L（Transform & Lighting）

```
┌─────────────────────────────────────────────────────┐
│               GeForce 256 架构                       │
├─────────────────────────────────────────────────────┤
│  ┌─────────┐  ┌──────────┐  ┌─────────┐           │
│  │ T&L单元  │→│ 光栅化器  │→│ 像素管线 │           │
│  │(硬件固定)│  │          │  │(4条并行) │           │
│  └─────────┘  └──────────┘  └─────────┘           │
│                                                     │
│  关键参数：                                          │
│  • 15M 晶体管                                       │
│  • 220nm 制程                                       │
│  • 480M 顶点/秒                                     │
│  • 4 像素管线                                       │
└─────────────────────────────────────────────────────┘
```

### 1.3 可编程着色器革命 (2001-2006)

**GeForce 3 (NV20, 2001)**：引入可编程顶点和像素着色器

```
┌───────────────────────────────────────────────────────┐
│                  GeForce 3 架构                        │
├───────────────────────────────────────────────────────┤
│  ┌──────────────┐           ┌──────────────┐         │
│  │ 顶点着色器    │           │ 像素着色器    │         │
│  │ (可编程)     │           │ (可编程)     │         │
│  │              │           │              │         │
│  │ • 128指令    │           │ • 12指令     │         │
│  │ • 16寄存器   │           │ • 4纹理单元  │         │
│  └──────────────┘           └──────────────┘         │
│                                                       │
│  nfiniteFX引擎：                                      │
│  • Vertex Shader 1.1                                 │
│  • Pixel Shader 1.1-1.4                              │
│  • 57M 晶体管                                         │
└───────────────────────────────────────────────────────┘
```

**GeForce FX (NV30, 2003)**：CineFX架构，32位浮点精度

```
着色器演进对比：
┌────────────┬──────────────┬──────────────┬──────────┐
│  架构      │ 顶点着色器    │ 像素着色器    │ 精度     │
├────────────┼──────────────┼──────────────┼──────────┤
│ GeForce 3  │ 128 指令     │ 12 指令      │ FP16     │
│ GeForce FX │ 256 指令     │ 1024 指令    │ FP32     │
│ GeForce 6  │ 512 指令     │ 无限制       │ FP32     │
└────────────┴──────────────┴──────────────┴──────────┘
```

### 1.4 统一着色器架构：Tesla时代 (2006-2010)

**G80/Tesla架构 (2006)**：革命性的统一着色器设计

```
┌─────────────────────────────────────────────────────────┐
│                    G80 统一架构                          │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  ┌─────────────────────────────────────────────┐       │
│  │           TPC (Texture Processing Cluster)   │ × 8   │
│  │  ┌────────────────────────────────────┐     │       │
│  │  │         SM (Streaming Multiprocessor)│ × 2│       │
│  │  │  ┌──────────────────────────────┐  │     │       │
│  │  │  │    SP (Scalar Processor)     │×8│     │       │
│  │  │  │  • 单精度浮点运算             │  │     │       │
│  │  │  │  • 1.35 GHz 频率             │  │     │       │
│  │  │  └──────────────────────────────┘  │     │       │
│  │  │                                     │     │       │
│  │  │  共享内存: 16KB                     │     │       │
│  │  │  寄存器: 8192 × 32-bit             │     │       │
│  │  └────────────────────────────────────┘     │       │
│  └─────────────────────────────────────────────┘       │
│                                                         │
│  总计: 128 CUDA 核心 (16 SM × 8 SP)                     │
│  晶体管: 681M (90nm)                                    │
└─────────────────────────────────────────────────────────┘
```

**关键创新**：
- 统一的标量处理器替代分离的顶点/像素单元
- 动态负载均衡，提高硬件利用率
- CUDA编程模型的硬件基础
- 首次引入共享内存概念

### 1.5 计算优化：Fermi架构 (2010)

**GF100/Fermi**：首个真正为计算设计的GPU架构

```
┌──────────────────────────────────────────────────────────┐
│                     Fermi SM 架构                        │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  ┌────────────────────────────────────────────┐         │
│  │              Fermi SM 详细结构              │         │
│  ├────────────────────────────────────────────┤         │
│  │                                            │         │
│  │  CUDA Core × 32:                           │         │
│  │  ┌──┐┌──┐┌──┐┌──┐ ... ┌──┐┌──┐           │         │
│  │  │CC││CC││CC││CC│     │CC││CC│           │         │
│  │  └──┘└──┘└──┘└──┘     └──┘└──┘           │         │
│  │                                            │         │
│  │  SFU (Special Function Unit) × 4:          │         │
│  │  ┌────┐┌────┐┌────┐┌────┐                │         │
│  │  │SFU ││SFU ││SFU ││SFU │                │         │
│  │  └────┘└────┘└────┘└────┘                │         │
│  │                                            │         │
│  │  LD/ST (Load/Store Unit) × 16             │         │
│  │                                            │         │
│  │  Warp Scheduler × 2 (双发射)               │         │
│  │                                            │         │
│  │  共享内存/L1缓存: 64KB (可配置)            │         │
│  │  寄存器文件: 32768 × 32-bit               │         │
│  └────────────────────────────────────────────┘         │
│                                                          │
│  架构特性：                                               │
│  • 双精度浮点支持 (FP64)                                  │
│  • ECC 内存纠错                                          │
│  • 并发内核执行                                          │
│  • 统一内存地址空间                                       │
└──────────────────────────────────────────────────────────┘
```

### 1.6 能效革命：Kepler架构 (2012)

**GK110/Kepler**：追求能效比的架构优化

```
┌───────────────────────────────────────────────────────────┐
│                    Kepler SMX 架构                        │
├───────────────────────────────────────────────────────────┤
│                                                           │
│  SMX (Next-Gen SM) 结构：                                 │
│  ┌─────────────────────────────────────────────┐         │
│  │  CUDA Core × 192 (6× Fermi)                 │         │
│  │  ┌────────────────────────────────┐         │         │
│  │  │   32 CUDA Cores × 6 分区        │         │         │
│  │  │   每分区独立调度                 │         │         │
│  │  └────────────────────────────────┘         │         │
│  │                                             │         │
│  │  DP Unit × 64 (双精度单元)                  │         │
│  │  SFU × 32                                   │         │
│  │  LD/ST × 32                                 │         │
│  │                                             │         │
│  │  Warp Scheduler × 4 (四发射)                │         │
│  │  指令调度器 × 8                              │         │
│  │                                             │         │
│  │  寄存器: 65536 × 32-bit                     │         │
│  │  共享内存: 48KB                              │         │
│  │  L1/纹理缓存: 48KB                          │         │
│  └─────────────────────────────────────────────┘         │
│                                                           │
│  关键创新：                                                │
│  • 动态并行 (Dynamic Parallelism)                         │
│  • Hyper-Q (32个硬件工作队列)                             │
│  • 3倍能效比提升                                          │
└───────────────────────────────────────────────────────────┘
```

### 1.7 效率优化：Maxwell架构 (2014)

**GM204/Maxwell**：架构重设计，极致能效

```
┌────────────────────────────────────────────────────────────┐
│                    Maxwell SMM 架构                        │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  SMM 分区设计：                                             │
│  ┌──────────────────────────────────────────────┐         │
│  │            4个独立处理块 (Quad)               │         │
│  │  ┌──────────┐ ┌──────────┐                  │         │
│  │  │ Quad 0   │ │ Quad 1   │                  │         │
│  │  │ 32 Cores │ │ 32 Cores │                  │         │
│  │  │ 8 LD/ST  │ │ 8 LD/ST  │                  │         │
│  │  │ 8 SFU    │ │ 8 SFU    │                  │         │
│  │  └──────────┘ └──────────┘                  │         │
│  │                                              │         │
│  │  ┌──────────┐ ┌──────────┐                  │         │
│  │  │ Quad 2   │ │ Quad 3   │                  │         │
│  │  │ 32 Cores │ │ 32 Cores │                  │         │
│  │  │ 8 LD/ST  │ │ 8 LD/ST  │                  │         │
│  │  │ 8 SFU    │ │ 8 SFU    │                  │         │
│  │  └──────────┘ └──────────┘                  │         │
│  │                                              │         │
│  │  共享资源：                                   │         │
│  │  • 96KB 共享内存                             │         │
│  │  • 64K 32-bit 寄存器                         │         │
│  │  • 4个Warp调度器 (每Quad一个)                │         │
│  └──────────────────────────────────────────────┘         │
│                                                            │
│  架构改进：                                                 │
│  • 2倍能效比 vs Kepler                                     │
│  • 更大的L2缓存 (2MB)                                      │
│  • 简化的调度逻辑                                          │
└────────────────────────────────────────────────────────────┘
```

### 1.8 深度学习时代：Pascal架构 (2016)

**GP100/Pascal**：为深度学习优化的架构

```
┌────────────────────────────────────────────────────────────┐
│                     Pascal SM 架构                         │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  关键硬件单元：                                             │
│  ┌──────────────────────────────────────────────┐         │
│  │  FP32 CUDA Core × 64                         │         │
│  │  FP64 DP Unit × 32 (1:2 比率)                │         │
│  │  LD/ST Unit × 32                             │         │
│  │  SFU × 16                                    │         │
│  │                                              │         │
│  │  新特性：                                     │         │
│  │  • FP16 运算支持 (2× 吞吐量)                 │         │
│  │  • 页面迁移引擎                              │         │
│  │  • 统一内存 & 虚拟寻址                       │         │
│  │  • NVLink 1.0 支持                           │         │
│  └──────────────────────────────────────────────┘         │
│                                                            │
│  HBM2 内存特性：                                            │
│  • 4096-bit 位宽                                          │
│  • 732 GB/s 带宽                                          │
│  • 16GB 容量                                              │
└────────────────────────────────────────────────────────────┘
```

### 1.9 Tensor Core革命：Volta架构 (2017)

**GV100/Volta**：引入专用AI加速单元

```
┌────────────────────────────────────────────────────────────┐
│                      Volta SM 架构                         │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  ┌──────────────────────────────────────────────┐         │
│  │            Volta SM 处理单元分布              │         │
│  │                                              │         │
│  │  4个处理块，每块包含：                        │         │
│  │  ┌────────────────────────┐                 │         │
│  │  │ • 16 FP32 Core         │                 │         │
│  │  │ • 8 FP64 Core          │                 │         │
│  │  │ • 16 INT32 Core        │                 │         │
│  │  │ • 2 Tensor Core ← 新！  │                 │         │
│  │  │ • 8 LD/ST Unit         │                 │         │
│  │  │ • 4 SFU                │                 │         │
│  │  └────────────────────────┘                 │         │
│  │                                              │         │
│  │  SM总计：                                     │         │
│  │  • 64 FP32 + 64 INT32 (独立数据路径)         │         │
│  │  • 32 FP64                                   │         │
│  │  • 8 Tensor Core                             │         │
│  │  • 128KB L1/共享内存                         │         │
│  └──────────────────────────────────────────────┘         │
│                                                            │
│  Tensor Core 运算模式：                                     │
│  ┌──────────────────────────────────────────────┐         │
│  │     D = A × B + C  (4×4 矩阵运算)            │         │
│  │                                              │         │
│  │     输入: A[4×4] FP16                        │         │
│  │          B[4×4] FP16                        │         │
│  │     累加: C[4×4] FP32                        │         │
│  │     输出: D[4×4] FP32                        │         │
│  │                                              │         │
│  │     每Tensor Core每时钟: 64 FMA = 128 FLOPS  │         │
│  └──────────────────────────────────────────────┘         │
└────────────────────────────────────────────────────────────┘
```

### 1.10 光线追踪时代：Turing架构 (2018)

**TU102/Turing**：实时光线追踪 + AI

```
┌────────────────────────────────────────────────────────────┐
│                     Turing SM 架构                         │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  多功能SM设计：                                             │
│  ┌──────────────────────────────────────────────┐         │
│  │                                              │         │
│  │   并行执行单元：                              │         │
│  │   ┌──────────────────────────┐              │         │
│  │   │ FP32 数据路径             │              │         │
│  │   │ • 64 FP32 CUDA Core      │              │         │
│  │   └──────────────────────────┘              │         │
│  │                                              │         │
│  │   ┌──────────────────────────┐              │         │
│  │   │ INT32 数据路径            │              │         │
│  │   │ • 64 INT32 Core          │              │         │
│  │   └──────────────────────────┘              │         │
│  │                                              │         │
│  │   ┌──────────────────────────┐              │         │
│  │   │ Tensor Core (Gen 2)      │              │         │
│  │   │ • 8个 Tensor Core        │              │         │
│  │   │ • FP16/INT8/INT4 支持    │              │         │
│  │   └──────────────────────────┘              │         │
│  │                                              │         │
│  │   ┌──────────────────────────┐              │         │
│  │   │ RT Core ← 革命性创新！     │              │         │
│  │   │ • BVH 遍历               │              │         │
│  │   │ • 光线-三角形相交测试     │              │         │
│  │   └──────────────────────────┘              │         │
│  │                                              │         │
│  │   96KB L1/共享内存                           │         │
│  └──────────────────────────────────────────────┘         │
└────────────────────────────────────────────────────────────┘
```

### 1.11 稀疏计算：Ampere架构 (2020)

**GA100/Ampere**：第三代Tensor Core与结构化稀疏

```
┌────────────────────────────────────────────────────────────┐
│                     Ampere SM 架构                         │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  第三代Tensor Core特性：                                    │
│  ┌──────────────────────────────────────────────┐         │
│  │  数据类型支持：                                │         │
│  │  ┌─────────────────────────────────┐        │         │
│  │  │ • FP64 (新增): 双精度矩阵运算     │        │         │
│  │  │ • TF32 (新增): 19-bit精度        │        │         │
│  │  │ • BF16: Brain Float              │        │         │
│  │  │ • FP16: 半精度                   │        │         │
│  │  │ • INT8/INT4/Binary               │        │         │
│  │  └─────────────────────────────────┘        │         │
│  │                                              │         │
│  │  结构化稀疏 (2:4)：                          │         │
│  │  ┌─────────────────────────────────┐        │         │
│  │  │ 原始矩阵:  [1 0 2 0 3 0 4 0]    │        │         │
│  │  │            ↓ 2:4 稀疏化          │        │         │
│  │  │ 稀疏矩阵:  [1 2 _ _ 3 4 _ _]    │        │         │
│  │  │ 索引:      [0 2 4 6]            │        │         │
│  │  │ 结果: 2× 有效吞吐量              │        │         │
│  │  └─────────────────────────────────┘        │         │
│  └──────────────────────────────────────────────┘         │
│                                                            │
│  SM计算单元：                                               │
│  • 128 FP32 CUDA Core (2× vs Volta)                      │
│  • 64 FP64 Core                                           │
│  • 4个第三代 Tensor Core                                  │
│  • 192KB L1/共享内存                                      │
└────────────────────────────────────────────────────────────┘
```

### 1.12 Transformer引擎：Hopper架构 (2022)

**GH100/Hopper**：为大语言模型优化

```
┌────────────────────────────────────────────────────────────┐
│                      Hopper SM 架构                        │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  Transformer Engine：                                      │
│  ┌──────────────────────────────────────────────┐         │
│  │  动态精度选择：                                │         │
│  │  ┌─────────────────────────────────┐        │         │
│  │  │ 输入张量 → 统计分析               │        │         │
│  │  │    ↓                             │        │         │
│  │  │ 选择最优精度 (FP8/FP16/BF16)     │        │         │
│  │  │    ↓                             │        │         │
│  │  │ Tensor Core 执行                 │        │         │
│  │  │    ↓                             │        │         │
│  │  │ 自动缩放 & 输出                  │        │         │
│  │  └─────────────────────────────────┘        │         │
│  │                                              │         │
│  │  FP8 格式 (E4M3 & E5M2)：                    │         │
│  │  • E4M3: 4位指数, 3位尾数 (更高精度)        │         │
│  │  • E5M2: 5位指数, 2位尾数 (更大范围)        │         │
│  └──────────────────────────────────────────────┘         │
│                                                            │
│  DPX指令集：                                                │
│  • 动态编程加速指令                                        │
│  • Smith-Waterman算法 7000× 加速                          │
│  • 生物信息学应用优化                                      │
│                                                            │
│  SM规格：                                                  │
│  • 128 FP32 CUDA Core                                     │
│  • 4个第四代 Tensor Core                                  │
│  • 256KB L1/共享内存 (业界最大)                            │
└────────────────────────────────────────────────────────────┘
```

### 1.13 第二代Transformer引擎：Blackwell架构 (2024)

**GB100/Blackwell**：双芯片设计的极限扩展

```
┌────────────────────────────────────────────────────────────┐
│                    Blackwell SM 架构                       │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  双Die设计：                                                │
│  ┌──────────────────────────────────────────────┐         │
│  │     Die 0              Die 1                 │         │
│  │  ┌─────────┐  10TB/s  ┌─────────┐          │         │
│  │  │ 104 SM  │ ←──────→ │ 104 SM  │          │         │
│  │  │1040亿晶体│          │1040亿晶体│          │         │
│  │  └─────────┘          └─────────┘          │         │
│  │                                              │         │
│  │  总计: 208 SM, 2080亿晶体管                  │         │
│  └──────────────────────────────────────────────┘         │
│                                                            │
│  第五代Tensor Core：                                       │
│  • FP4精度支持 (业界首创)                                  │
│  • 20 PFLOPS FP4性能                                      │
│  • 微缩放 (Microscaling) 技术                             │
│                                                            │
│  新增硬件单元：                                             │
│  • 可靠性引擎 (RAS)                                        │
│  • 安全引擎 (加密计算)                                     │
│  • 解压缩引擎 (5× 带宽节省)                                │
└────────────────────────────────────────────────────────────┘
```

## 2. 内存架构革新

### 2.1 内存带宽的演进

GPU的性能很大程度上受限于内存带宽，这就是著名的"内存墙"问题。NVIDIA通过多种技术创新持续突破这一瓶颈：

```
内存带宽演进时间线：
┌──────────────────────────────────────────────────────────┐
│ 年份  │ 架构      │ 内存类型   │ 位宽   │ 带宽        │
├──────────────────────────────────────────────────────────┤
│ 1999 │ GeForce   │ SDR       │ 128-bit│ 2.7 GB/s    │
│ 2001 │ GeForce 3 │ DDR       │ 128-bit│ 8 GB/s      │
│ 2006 │ G80       │ GDDR3     │ 384-bit│ 86 GB/s     │
│ 2010 │ Fermi     │ GDDR5     │ 384-bit│ 192 GB/s    │
│ 2016 │ Pascal    │ HBM2      │ 4096-bit│ 732 GB/s   │
│ 2017 │ Volta     │ HBM2      │ 4096-bit│ 900 GB/s   │
│ 2020 │ Ampere    │ HBM2e     │ 5120-bit│ 1555 GB/s  │
│ 2022 │ Hopper    │ HBM3      │ 5120-bit│ 3350 GB/s  │
│ 2024 │ Blackwell │ HBM3e     │ 8192-bit│ 8000 GB/s  │
└──────────────────────────────────────────────────────────┘
```

### 2.2 缓存层次结构演进

#### 早期简单缓存 (1999-2006)
```
┌─────────────────────────────────────┐
│       GeForce - GeForce 6           │
├─────────────────────────────────────┤
│  SM → 纹理缓存 → 显存               │
│       (只读)                        │
└─────────────────────────────────────┘
```

#### 引入共享内存 (2006)
```
┌─────────────────────────────────────────────┐
│              G80/Tesla                       │
├─────────────────────────────────────────────┤
│  ┌──────┐  ┌──────────┐  ┌──────┐         │
│  │  SM  │→│ 共享内存  │→│ L2   │→ 显存   │
│  │      │  │  16KB     │  │256KB │         │
│  └──────┘  └──────────┘  └──────┘         │
└─────────────────────────────────────────────┘
```

#### 统一L1/共享内存 (2010)
```
┌──────────────────────────────────────────────────┐
│                  Fermi                           │
├──────────────────────────────────────────────────┤
│  ┌──────┐  ┌────────────────┐  ┌──────┐       │
│  │  SM  │→│ L1/共享内存     │→│  L2  │→显存  │
│  │      │  │ 64KB (可配置)   │  │768KB │       │
│  └──────┘  │ 48KB+16KB 或    │  └──────┘       │
│            │ 16KB+48KB       │                  │
│            └────────────────┘                  │
└──────────────────────────────────────────────────┘
```

#### 现代多级缓存 (2017-2024)
```
┌────────────────────────────────────────────────────────┐
│              Volta/Ampere/Hopper                       │
├────────────────────────────────────────────────────────┤
│                                                        │
│  ┌─────────────────────────────────────────┐          │
│  │  SM内部缓存层次                          │          │
│  │  ┌──────────────────────────┐          │          │
│  │  │ 寄存器文件 (256KB)        │          │          │
│  │  └──────────────────────────┘          │          │
│  │           ↓                             │          │
│  │  ┌──────────────────────────┐          │          │
│  │  │ L0 指令缓存               │          │          │
│  │  └──────────────────────────┘          │          │
│  │           ↓                             │          │
│  │  ┌──────────────────────────┐          │          │
│  │  │ L1/共享内存 (128-256KB)   │          │          │
│  │  └──────────────────────────┘          │          │
│  └─────────────────────────────────────────┘          │
│                    ↓                                   │
│  ┌──────────────────────────────────────────┐         │
│  │         L2 缓存 (4-60MB)                  │         │
│  └──────────────────────────────────────────┘         │
│                    ↓                                   │
│  ┌──────────────────────────────────────────┐         │
│  │         HBM 内存 (16-192GB)               │         │
│  └──────────────────────────────────────────┘         │
└────────────────────────────────────────────────────────┘
```

### 2.3 HBM技术革命

#### HBM vs GDDR对比
```
┌───────────────────────────────────────────────────────┐
│                   HBM vs GDDR                         │
├───────────────────────────────────────────────────────┤
│                                                       │
│  GDDR布局：                                           │
│  ┌─────────┐                                        │
│  │   GPU   │←→ [GDDR] [GDDR] [GDDR] [GDDR]         │
│  └─────────┘   外围芯片，PCB走线                     │
│                                                       │
│  HBM布局：                                            │
│  ┌──────────────────────┐                           │
│  │  ┌─────┐ ┌─────┐   │ 硅中介层                   │
│  │  │ GPU │ │ HBM │   │ (Interposer)               │
│  │  └─────┘ └─────┘   │                           │
│  └──────────────────────┘                           │
│                                                       │
│  关键差异：                                           │
│  • 位宽: GDDR 32-bit vs HBM 1024-bit per stack     │
│  • 频率: GDDR 高频 vs HBM 低频                       │
│  • 功耗: HBM 功耗效率 3× 更优                        │
│  • 容量: HBM 单栈可达 24GB                          │
└───────────────────────────────────────────────────────┘
```

#### HBM代际演进
```
┌─────────────────────────────────────────────────────────┐
│ 代际  │ 规格      │ 单栈带宽  │ 容量   │ 采用GPU      │
├─────────────────────────────────────────────────────────┤
│ HBM1 │ 1Gbps/pin │ 128GB/s  │ 4GB   │ Fiji (AMD)   │
│ HBM2 │ 2Gbps/pin │ 256GB/s  │ 8GB   │ Pascal/Volta │
│ HBM2e│ 3.6Gbps   │ 461GB/s  │ 16GB  │ Ampere       │
│ HBM3 │ 6.4Gbps   │ 819GB/s  │ 24GB  │ Hopper       │
│ HBM3e│ 9.6Gbps   │ 1.2TB/s  │ 36GB  │ Blackwell    │
└─────────────────────────────────────────────────────────┘
```

### 2.4 内存压缩技术

#### 第三代Delta颜色压缩 (Maxwell, 2014)
```
压缩率提升：
原始数据: ████████████████ (100%)
压缩后:   ████████ (50% - 2:1压缩)
有效带宽: 2× 提升
```

#### 第四代压缩 (Pascal, 2016)
- 4:1和8:1压缩模式
- 智能压缩决策
- Z-buffer压缩优化

#### 计算数据压缩 (Hopper, 2022)
```
┌──────────────────────────────────────────┐
│        Hopper 压缩引擎                    │
├──────────────────────────────────────────┤
│  训练数据 → 压缩 → 传输 → 解压 → 计算    │
│           5:1    ↑5×带宽               │
└──────────────────────────────────────────┘
```

### 2.5 虚拟内存与统一寻址

#### 统一虚拟寻址 (UVA) - Fermi (2010)
```
┌─────────────────────────────────────────┐
│         统一地址空间                     │
├─────────────────────────────────────────┤
│  CPU内存  │  GPU内存  │  共享内存       │
│  0x0000.. │ 0x8000.. │ 0xF000..       │
│           ↑                            │
│      单一指针可访问所有内存              │
└─────────────────────────────────────────┘
```

#### 统一内存 (UM) - Pascal (2016)
```
自动页面迁移：
┌────────┐  页面故障  ┌────────┐
│  CPU   │←─────────→│  GPU   │
│ Memory │  自动迁移  │ Memory │
└────────┘           └────────┘
```

### 2.6 多GPU内存互连

#### NVLink内存池化
```
┌──────────────────────────────────────────────┐
│           NVLink 内存池                       │
├──────────────────────────────────────────────┤
│  ┌─────┐ NVLink ┌─────┐ NVLink ┌─────┐     │
│  │GPU0 │←──────→│GPU1 │←──────→│GPU2 │     │
│  │80GB │        │80GB │        │80GB │     │
│  └─────┘        └─────┘        └─────┘     │
│                                              │
│  逻辑视图: 240GB 统一内存空间                 │
└──────────────────────────────────────────────┘
```

## 3. 互连技术发展（NVLink、NVSwitch）

### 3.1 PCIe瓶颈与突破

#### PCIe带宽限制
```
┌──────────────────────────────────────────────────┐
│            PCIe 带宽演进                          │
├──────────────────────────────────────────────────┤
│ PCIe 1.0 x16:  4 GB/s  (2003)                   │
│ PCIe 2.0 x16:  8 GB/s  (2007)                   │
│ PCIe 3.0 x16: 16 GB/s  (2010)                   │
│ PCIe 4.0 x16: 32 GB/s  (2017)                   │
│ PCIe 5.0 x16: 64 GB/s  (2022)                   │
│                                                  │
│ 问题: GPU内存带宽 3000+ GB/s                     │
│      PCIe带宽仅 32-64 GB/s                      │
│      瓶颈比率: 50:1                             │
└──────────────────────────────────────────────────┘
```

### 3.2 NVLink技术演进

#### NVLink 1.0 (Pascal, 2016)
```
┌──────────────────────────────────────────────────┐
│              NVLink 1.0 架构                      │
├──────────────────────────────────────────────────┤
│                                                  │
│  单链路: 40 GB/s (双向)                          │
│  最大链路数: 4                                   │
│  总带宽: 160 GB/s                               │
│                                                  │
│  ┌──────┐  4×NVLink  ┌──────┐                  │
│  │ GPU0 │◄═════════►│ GPU1 │                  │
│  └──────┘   160GB/s  └──────┘                  │
│                                                  │
│  对比PCIe 3.0: 10× 带宽提升                      │
└──────────────────────────────────────────────────┘
```

#### NVLink 2.0 (Volta, 2017)
```
┌──────────────────────────────────────────────────┐
│              NVLink 2.0 增强                      │
├──────────────────────────────────────────────────┤
│                                                  │
│  单链路: 50 GB/s                                 │
│  最大链路数: 6                                   │
│  总带宽: 300 GB/s                               │
│                                                  │
│  新特性:                                         │
│  • CPU-GPU 连接支持 (IBM POWER9)                 │
│  • 缓存一致性协议                                │
│  • 原子操作支持                                  │
└──────────────────────────────────────────────────┘
```

#### NVLink 3.0 (Ampere, 2020)
```
┌──────────────────────────────────────────────────┐
│              NVLink 3.0 规格                      │
├──────────────────────────────────────────────────┤
│                                                  │
│  单链路: 50 GB/s                                 │
│  最大链路数: 12 (A100)                           │
│  总带宽: 600 GB/s                               │
│                                                  │
│  ┌─────┐ 12×NVLink ┌─────┐                     │
│  │ A100│◄═════════►│ A100│                     │
│  └─────┘  600GB/s  └─────┘                     │
└──────────────────────────────────────────────────┘
```

#### NVLink 4.0 (Hopper, 2022)
```
┌──────────────────────────────────────────────────┐
│              NVLink 4.0 飞跃                      │
├──────────────────────────────────────────────────┤
│                                                  │
│  单链路: 100 GB/s (2× 提升)                      │
│  最大链路数: 18                                  │
│  总带宽: 900 GB/s (单向)                        │
│                                                  │
│  新增特性:                                       │
│  • NVLink Switch 系统支持                        │
│  • 256 GPU 全连接拓扑                           │
└──────────────────────────────────────────────────┘
```

#### NVLink 5.0 (Blackwell, 2024)
```
┌──────────────────────────────────────────────────┐
│              NVLink 5.0 极限                      │
├──────────────────────────────────────────────────┤
│                                                  │
│  单链路: 200 GB/s                                │
│  最大链路数: 18                                  │
│  总带宽: 1.8 TB/s (单向)                        │
│                                                  │
│  芯片间互连: 10 TB/s (双Die)                     │
└──────────────────────────────────────────────────┘
```

### 3.3 NVSwitch：全连接拓扑

#### 第一代 NVSwitch (2018)
```
┌────────────────────────────────────────────────────┐
│           第一代 NVSwitch (DGX-2)                  │
├────────────────────────────────────────────────────┤
│                                                    │
│  NVSwitch 芯片规格:                                │
│  • 18个 NVLink 2.0 端口                           │
│  • 900 GB/s 总带宽                                │
│  • 2亿晶体管                                      │
│                                                    │
│  DGX-2 拓扑 (16 GPU全连接):                        │
│                                                    │
│      ┌──────────────────────┐                     │
│      │    6× NVSwitch        │                     │
│      └──────┬───────────────┘                     │
│             │                                      │
│    ┌────────┼────────┐                           │
│    ▼        ▼        ▼                           │
│  ┌───┐   ┌───┐    ┌───┐                         │
│  │GPU│···│GPU│····│GPU│  16个V100                │
│  └───┘   └───┘    └───┘                         │
│                                                    │
│  任意两GPU间: 300 GB/s                            │
│  总切换带宽: 2.4 TB/s                             │
└────────────────────────────────────────────────────┘
```

#### 第二代 NVSwitch (2020)
```
┌────────────────────────────────────────────────────┐
│           第二代 NVSwitch (DGX A100)               │
├────────────────────────────────────────────────────┤
│                                                    │
│  增强特性:                                         │
│  • NVLink 3.0 支持                                │
│  • 36个端口                                       │
│  • 单芯片 1.8 TB/s                                │
│                                                    │
│  系统拓扑:                                        │
│  ┌─────────────────────────────┐                 │
│  │      6× NVSwitch 2.0        │                 │
│  └─────────┬───────────────────┘                 │
│            │                                       │
│   8× A100 全互连                                  │
│   GPU间带宽: 600 GB/s                             │
└────────────────────────────────────────────────────┘
```

#### 第三代 NVSwitch (2022)
```
┌────────────────────────────────────────────────────┐
│           第三代 NVSwitch (Hopper)                 │
├────────────────────────────────────────────────────┤
│                                                    │
│  革命性提升:                                       │
│  • NVLink 4.0 (100 GB/s per link)                │
│  • 64个 NVLink 端口                               │
│  • 单芯片 3.2 TB/s                                │
│  • 支持 256 GPU 系统                              │
│                                                    │
│  超大规模拓扑:                                    │
│                                                    │
│        ┌────────────────┐                         │
│        │  NVSwitch 网络  │                         │
│        │   (2层架构)    │                         │
│        └────────────────┘                         │
│               │                                    │
│     ┌─────────┼─────────┐                        │
│     ▼         ▼         ▼                        │
│  256× H100 GPU 全连接                             │
│  任意GPU间: 900 GB/s                              │
└────────────────────────────────────────────────────┘
```

### 3.4 系统级互连架构

#### DGX SuperPOD架构
```
┌────────────────────────────────────────────────────┐
│              DGX SuperPOD 架构                     │
├────────────────────────────────────────────────────┤
│                                                    │
│  层次化网络:                                       │
│                                                    │
│  第1层: NVLink (GPU内部)                          │
│  ┌───┐─NVLink─┌───┐                              │
│  │GPU│        │GPU│  900 GB/s                    │
│  └───┘        └───┘                              │
│                                                    │
│  第2层: NVSwitch (节点内)                         │
│  ┌─────────────────┐                             │
│  │   8 GPU/节点    │  600 GB/s GPU间             │
│  └─────────────────┘                             │
│                                                    │
│  第3层: InfiniBand (节点间)                       │
│  ┌──────┐ IB ┌──────┐                           │
│  │ Node │────│ Node │  400 Gb/s                  │
│  └──────┘    └──────┘                           │
│                                                    │
│  扩展性: 256+ 节点, 2000+ GPU                     │
└────────────────────────────────────────────────────┘
```

### 3.5 未来互连技术展望

#### UCIe (通用芯片互连)
```
┌────────────────────────────────────────────────────┐
│           UCIe Chiplet 互连                        │
├────────────────────────────────────────────────────┤
│                                                    │
│  ┌──────┐ ┌──────┐ ┌──────┐ ┌──────┐           │
│  │ GPU  │ │ CPU  │ │ HBM  │ │ I/O  │           │
│  │Chiplet│ │Chiplet│ │Chiplet│ │Chiplet│        │
│  └───┬──┘ └───┬──┘ └───┬──┘ └───┬──┘           │
│      └────────┼────────┼────────┘                │
│               │  UCIe  │                          │
│            ┌──┴────────┴──┐                      │
│            │  硅中介层     │                      │
│            └──────────────┘                      │
│                                                    │
│  带宽密度: 10+ TB/s/mm                           │
│  延迟: < 2ns                                      │
│  功耗: 0.1 pJ/bit                                │
└────────────────────────────────────────────────────┘
```

## 4. 架构综合对比分析

### 4.1 计算能力演进总览

```
┌───────────────────────────────────────────────────────────────┐
│                    GPU架构计算能力对比                         │
├──────────┬────────┬──────────┬──────────┬─────────┬─────────┤
│ 架构     │ 年份   │ CUDA核心  │ Tensor   │ FP32    │ FP16   │
│          │        │          │ Core     │ TFLOPS  │ TFLOPS │
├──────────┼────────┼──────────┼──────────┼─────────┼─────────┤
│ Tesla    │ 2006   │ 128      │ -        │ 0.35    │ -      │
│ Fermi    │ 2010   │ 512      │ -        │ 1.03    │ -      │
│ Kepler   │ 2012   │ 2880     │ -        │ 3.95    │ -      │
│ Maxwell  │ 2014   │ 2048     │ -        │ 4.61    │ -      │
│ Pascal   │ 2016   │ 3840     │ -        │ 10.6    │ 21.2   │
│ Volta    │ 2017   │ 5120     │ 640      │ 15.7    │ 125    │
│ Turing   │ 2018   │ 4608     │ 576      │ 16.3    │ 130    │
│ Ampere   │ 2020   │ 6912     │ 432      │ 19.5    │ 312    │
│ Hopper   │ 2022   │ 16896    │ 528      │ 67      │ 1979   │
│ Blackwell│ 2024   │ 20480    │ 640      │ 90      │ 2500   │
└──────────┴────────┴──────────┴──────────┴─────────┴─────────┘
```

### 4.2 内存系统演进对比

```
┌──────────────────────────────────────────────────────────────┐
│                    内存子系统关键指标                         │
├──────────┬────────┬──────────┬─────────┬──────────┬────────┤
│ 架构     │ 内存   │ 带宽     │ L2缓存  │ 共享内存 │ 压缩   │
│          │ 类型   │ (GB/s)   │ (MB)    │ (KB/SM)  │        │
├──────────┼────────┼──────────┼─────────┼──────────┼────────┤
│ Tesla    │ GDDR3  │ 141      │ 0.25    │ 16       │ 无     │
│ Fermi    │ GDDR5  │ 192      │ 0.75    │ 48/16    │ 无     │
│ Kepler   │ GDDR5  │ 288      │ 1.5     │ 48       │ 无     │
│ Maxwell  │ GDDR5  │ 336      │ 2       │ 96       │ 2:1    │
│ Pascal   │ HBM2   │ 732      │ 4       │ 64       │ 4:1    │
│ Volta    │ HBM2   │ 900      │ 6       │ 128      │ 4:1    │
│ Ampere   │ HBM2e  │ 1555     │ 40      │ 192      │ 4:1    │
│ Hopper   │ HBM3   │ 3350     │ 60      │ 256      │ 5:1    │
│ Blackwell│ HBM3e  │ 8000     │ 96      │ 256      │ 8:1    │
└──────────┴────────┴──────────┴─────────┴──────────┴────────┘
```

### 4.3 功耗效率演进

```
┌──────────────────────────────────────────────────────────────┐
│                    能效比演进 (GFLOPS/W)                      │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│  100 ┤                                      ╱ Blackwell     │
│      │                                    ╱                  │
│   80 ┤                                  ╱ Hopper            │
│      │                                ╱                      │
│   60 ┤                              ╱                        │
│      │                            ╱ Ampere                   │
│   40 ┤                          ╱                            │
│      │                        ╱ Volta                        │
│   20 ┤                    ╱─ Pascal                          │
│      │               ╱─── Maxwell                            │
│   10 ┤         ╱──── Kepler                                  │
│      │    ╱──── Fermi                                        │
│    5 ┤╱─── Tesla                                             │
│      └──────────────────────────────────────────────────────┤
│       2006  2010  2012  2014  2016  2018  2020  2022  2024 │
└──────────────────────────────────────────────────────────────┘
```

### 4.4 技术创新里程碑总结

```
┌──────────────────────────────────────────────────────────────┐
│                    关键技术创新时间线                          │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│ 1999: GPU概念诞生 (硬件T&L)                                  │
│   │                                                          │
│ 2001: 可编程着色器                                           │
│   │                                                          │
│ 2006: 统一着色器架构 + CUDA                                  │
│   │                                                          │
│ 2010: 双精度计算 + ECC内存                                   │
│   │                                                          │
│ 2012: 动态并行 + Hyper-Q                                     │
│   │                                                          │
│ 2016: HBM内存 + NVLink + 统一内存                            │
│   │                                                          │
│ 2017: Tensor Core (AI加速)                                   │
│   │                                                          │
│ 2018: RT Core (实时光追) + NVSwitch                          │
│   │                                                          │
│ 2020: 稀疏计算 + 多精度支持                                   │
│   │                                                          │
│ 2022: Transformer引擎 + FP8                                  │
│   │                                                          │
│ 2024: 双Die设计 + FP4精度                                    │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

## 5. 架构设计哲学演变

### 5.1 从专用到通用的转变

```
第一阶段 (1999-2006): 图形专用
• 固定功能管线
• 顶点/像素分离处理
• 优化光栅化性能

第二阶段 (2006-2016): 通用计算觉醒
• 统一着色器架构
• CUDA编程模型
• 科学计算应用

第三阶段 (2017-至今): AI专用加速
• Tensor Core矩阵运算
• 混合精度训练
• Transformer专用引擎
```

### 5.2 架构设计权衡

#### 面积分配策略演变
```
┌──────────────────────────────────────────────────────────────┐
│                    芯片面积分配演变                           │
├──────────────────────────────────────────────────────────────┤
│                                                              │
│  Kepler (2012):                                              │
│  ████████████████████░░░░░ 80% CUDA核心, 20% 其他           │
│                                                              │
│  Volta (2017):                                               │
│  ████████████░░░░░░░░░░░░ 60% CUDA, 15% Tensor, 25% 其他   │
│                                                              │
│  Hopper (2022):                                              │
│  ██████░░░░░░░░░░░░░░░░░░ 40% CUDA, 35% Tensor, 25% 其他   │
│                                                              │
│  Blackwell (2024):                                           │
│  ████░░░░░░░░░░░░░░░░░░░░ 30% CUDA, 45% AI, 25% 其他       │
│                                                              │
└──────────────────────────────────────────────────────────────┘
```

### 5.3 未来架构趋势预测

```
2025-2030 技术方向：

1. 芯片级系统 (Chiplet)
   • 模块化GPU设计
   • 异构集成
   • 3D封装技术

2. 近数据计算
   • 处理单元内嵌存储
   • 计算存储融合
   • 最小化数据移动

3. 专用加速器矩阵
   • LLM专用引擎
   • 视觉Transformer加速
   • 科学计算DSA

4. 量子-经典混合
   • 量子纠错协处理
   • 混合算法加速
   • 新型互连协议
```

## 本章总结

NVIDIA GPU架构的演进历程展现了计算平台设计的范式转变：

1. **架构创新驱动力**：从图形渲染需求到通用计算，再到AI训练，每个时代的应用需求都推动着架构的革新。

2. **系统级优化**：现代GPU不再是单一处理器，而是包含计算、内存、互连的完整系统，每个组件都经过精心优化。

3. **软硬件协同设计**：CUDA生态系统与硬件架构的紧密结合，创造了难以复制的技术壁垒。

4. **前瞻性布局**：NVIDIA在2006年推出CUDA、2017年引入Tensor Core的决策，都远早于市场需求爆发，展现了卓越的技术远见。

GPU架构的演进还在继续，随着AI大模型、元宇宙、量子计算等新兴应用的出现，未来的GPU架构必将迎来更多革命性创新。

---

*下一章：[第8章 - CUDA生态系统](chapter8.md)*
