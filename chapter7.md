# 第7章：GPU 架构演进

> 从固定功能管线到可编程并行处理器的技术革命

## 本章概览

NVIDIA GPU架构的演进历程是现代计算史上最重要的技术革新之一。从1999年GeForce 256定义GPU概念开始，经过25年的发展，GPU已经从专用图形处理器演变为通用并行计算平台，成为AI时代的核心基础设施。

本章将深入剖析三个核心技术维度：
1. **SM（Streaming Multiprocessor）演化史**：从固定功能单元到高度可编程的并行处理器
2. **内存架构革新**：从DDR到HBM，解决"内存墙"问题的技术演进
3. **互连技术发展**：NVLink和NVSwitch如何打破PCIe瓶颈，实现超大规模GPU集群

## 1. SM (Streaming Multiprocessor) 演化史

### 1.1 前GPU时代：固定功能管线 (1995-1999)

在GPU概念诞生之前，图形加速器采用固定功能管线架构：

```
┌──────────────────────────────────────────────────┐
│            NV1/RIVA 128 固定管线                  │
├──────────────────────────────────────────────────┤
│  顶点处理 → 光栅化 → 纹理映射 → 像素输出          │
│     ↓         ↓         ↓          ↓            │
│  [固定单元] [固定单元] [固定单元] [固定单元]      │
└──────────────────────────────────────────────────┘
```

**技术特征**：
- 每个处理阶段都是专用硬件单元
- 无法编程，只能通过固定API控制
- 效率高但灵活性极差
- 无法适应新的渲染算法

### 1.2 第一代GPU：硬件T&L时代 (1999-2001)

**GeForce 256 (NV10)**：定义GPU概念，引入硬件T&L（Transform & Lighting）

```
┌─────────────────────────────────────────────────────┐
│               GeForce 256 架构                       │
├─────────────────────────────────────────────────────┤
│  ┌─────────┐  ┌──────────┐  ┌─────────┐           │
│  │ T&L单元  │→│ 光栅化器  │→│ 像素管线 │           │
│  │(硬件固定)│  │          │  │(4条并行) │           │
│  └─────────┘  └──────────┘  └─────────┘           │
│                                                     │
│  关键参数：                                          │
│  • 15M 晶体管                                       │
│  • 220nm 制程                                       │
│  • 480M 顶点/秒                                     │
│  • 4 像素管线                                       │
└─────────────────────────────────────────────────────┘
```

### 1.3 可编程着色器革命 (2001-2006)

**GeForce 3 (NV20, 2001)**：引入可编程顶点和像素着色器

```
┌───────────────────────────────────────────────────────┐
│                  GeForce 3 架构                        │
├───────────────────────────────────────────────────────┤
│  ┌──────────────┐           ┌──────────────┐         │
│  │ 顶点着色器    │           │ 像素着色器    │         │
│  │ (可编程)     │           │ (可编程)     │         │
│  │              │           │              │         │
│  │ • 128指令    │           │ • 12指令     │         │
│  │ • 16寄存器   │           │ • 4纹理单元  │         │
│  └──────────────┘           └──────────────┘         │
│                                                       │
│  nfiniteFX引擎：                                      │
│  • Vertex Shader 1.1                                 │
│  • Pixel Shader 1.1-1.4                              │
│  • 57M 晶体管                                         │
└───────────────────────────────────────────────────────┘
```

**GeForce FX (NV30, 2003)**：CineFX架构，32位浮点精度

```
着色器演进对比：
┌────────────┬──────────────┬──────────────┬──────────┐
│  架构      │ 顶点着色器    │ 像素着色器    │ 精度     │
├────────────┼──────────────┼──────────────┼──────────┤
│ GeForce 3  │ 128 指令     │ 12 指令      │ FP16     │
│ GeForce FX │ 256 指令     │ 1024 指令    │ FP32     │
│ GeForce 6  │ 512 指令     │ 无限制       │ FP32     │
└────────────┴──────────────┴──────────────┴──────────┘
```

### 1.4 统一着色器架构：Tesla时代 (2006-2010)

**G80/Tesla架构 (2006)**：革命性的统一着色器设计

```
┌─────────────────────────────────────────────────────────┐
│                    G80 统一架构                          │
├─────────────────────────────────────────────────────────┤
│                                                         │
│  ┌─────────────────────────────────────────────┐       │
│  │           TPC (Texture Processing Cluster)   │ × 8   │
│  │  ┌────────────────────────────────────┐     │       │
│  │  │         SM (Streaming Multiprocessor)│ × 2│       │
│  │  │  ┌──────────────────────────────┐  │     │       │
│  │  │  │    SP (Scalar Processor)     │×8│     │       │
│  │  │  │  • 单精度浮点运算             │  │     │       │
│  │  │  │  • 1.35 GHz 频率             │  │     │       │
│  │  │  └──────────────────────────────┘  │     │       │
│  │  │                                     │     │       │
│  │  │  共享内存: 16KB                     │     │       │
│  │  │  寄存器: 8192 × 32-bit             │     │       │
│  │  └────────────────────────────────────┘     │       │
│  └─────────────────────────────────────────────┘       │
│                                                         │
│  总计: 128 CUDA 核心 (16 SM × 8 SP)                     │
│  晶体管: 681M (90nm)                                    │
└─────────────────────────────────────────────────────────┘
```

**关键创新**：
- 统一的标量处理器替代分离的顶点/像素单元
- 动态负载均衡，提高硬件利用率
- CUDA编程模型的硬件基础
- 首次引入共享内存概念

### 1.5 计算优化：Fermi架构 (2010)

**GF100/Fermi**：首个真正为计算设计的GPU架构

```
┌──────────────────────────────────────────────────────────┐
│                     Fermi SM 架构                        │
├──────────────────────────────────────────────────────────┤
│                                                          │
│  ┌────────────────────────────────────────────┐         │
│  │              Fermi SM 详细结构              │         │
│  ├────────────────────────────────────────────┤         │
│  │                                            │         │
│  │  CUDA Core × 32:                           │         │
│  │  ┌──┐┌──┐┌──┐┌──┐ ... ┌──┐┌──┐           │         │
│  │  │CC││CC││CC││CC│     │CC││CC│           │         │
│  │  └──┘└──┘└──┘└──┘     └──┘└──┘           │         │
│  │                                            │         │
│  │  SFU (Special Function Unit) × 4:          │         │
│  │  ┌────┐┌────┐┌────┐┌────┐                │         │
│  │  │SFU ││SFU ││SFU ││SFU │                │         │
│  │  └────┘└────┘└────┘└────┘                │         │
│  │                                            │         │
│  │  LD/ST (Load/Store Unit) × 16             │         │
│  │                                            │         │
│  │  Warp Scheduler × 2 (双发射)               │         │
│  │                                            │         │
│  │  共享内存/L1缓存: 64KB (可配置)            │         │
│  │  寄存器文件: 32768 × 32-bit               │         │
│  └────────────────────────────────────────────┘         │
│                                                          │
│  架构特性：                                               │
│  • 双精度浮点支持 (FP64)                                  │
│  • ECC 内存纠错                                          │
│  • 并发内核执行                                          │
│  • 统一内存地址空间                                       │
└──────────────────────────────────────────────────────────┘
```

### 1.6 能效革命：Kepler架构 (2012)

**GK110/Kepler**：追求能效比的架构优化

```
┌───────────────────────────────────────────────────────────┐
│                    Kepler SMX 架构                        │
├───────────────────────────────────────────────────────────┤
│                                                           │
│  SMX (Next-Gen SM) 结构：                                 │
│  ┌─────────────────────────────────────────────┐         │
│  │  CUDA Core × 192 (6× Fermi)                 │         │
│  │  ┌────────────────────────────────┐         │         │
│  │  │   32 CUDA Cores × 6 分区        │         │         │
│  │  │   每分区独立调度                 │         │         │
│  │  └────────────────────────────────┘         │         │
│  │                                             │         │
│  │  DP Unit × 64 (双精度单元)                  │         │
│  │  SFU × 32                                   │         │
│  │  LD/ST × 32                                 │         │
│  │                                             │         │
│  │  Warp Scheduler × 4 (四发射)                │         │
│  │  指令调度器 × 8                              │         │
│  │                                             │         │
│  │  寄存器: 65536 × 32-bit                     │         │
│  │  共享内存: 48KB                              │         │
│  │  L1/纹理缓存: 48KB                          │         │
│  └─────────────────────────────────────────────┘         │
│                                                           │
│  关键创新：                                                │
│  • 动态并行 (Dynamic Parallelism)                         │
│  • Hyper-Q (32个硬件工作队列)                             │
│  • 3倍能效比提升                                          │
└───────────────────────────────────────────────────────────┘
```

### 1.7 效率优化：Maxwell架构 (2014)

**GM204/Maxwell**：架构重设计，极致能效

```
┌────────────────────────────────────────────────────────────┐
│                    Maxwell SMM 架构                        │
├────────────────────────────────────────────────────────────┤
│                                                            │
│  SMM 分区设计：                                             │
│  ┌──────────────────────────────────────────────┐         │
│  │            4个独立处理块 (Quad)               │         │
│  │  ┌──────────┐ ┌──────────┐                  │         │
│  │  │ Quad 0   │ │ Quad 1   │                  │         │
│  │  │ 32 Cores │ │ 32 Cores │                  │         │
│  │  │ 8 LD/ST  │ │ 8 LD/ST  │                  │         │
│  │  │ 8 SFU    │ │ 8 SFU    │                  │         │
│  │  └──────────┘ └──────────┘                  │         │
│  │                                              │         │
│  │  ┌──────────┐ ┌──────────┐                  │         │
│  │  │ Quad 2   │ │ Quad 3   │                  │         │
│  │  │ 32 Cores │ │ 32 Cores │                  │         │
│  │  │ 8 LD/ST  │ │ 8 LD/ST  │                  │         │
│  │  │ 8 SFU    │ │ 8 SFU    │                  │         │
│  │  └──────────┘ └──────────┘                  │         │
│  │                                              │         │
│  │  共享资源：                                   │         │
│  │  • 96KB 共享内存                             │         │
│  │  • 64K 32-bit 寄存器                         │         │
│  │  • 4个Warp调度器 (每Quad一个)                │         │
│  └──────────────────────────────────────────────┘         │
│                                                            │
│  架构改进：                                                 │
│  • 2倍能效比 vs Kepler                                     │
│  • 更大的L2缓存 (2MB)                                      │
│  • 简化的调度逻辑                                          │
└────────────────────────────────────────────────────────────┘
```
